{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abddf18a-23c4-4684-a3cb-d6aa4cfc4cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q huggingface\n",
    "!pip install -q transformers\n",
    "!pip install -q pillow\n",
    "!pip install -q loguru\n",
    "!pip install -q pydantic\n",
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a195d6-ce49-4b92-add1-6aa200c422cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from transformers import OwlViTProcessor, OwlViTForObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98395948-5a69-451b-98b5-be1c2fb197ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399e333d-a46c-4cbb-a76b-0fbf7f01e3ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53410cd8186423d9ca5cc6a08ab59cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/392 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643c8f89370f4b90979ec7ccd9c7a161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/775 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f785bb29e543e6aeddfbb7d27cd22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8aff8d8ee714c4f8910beb5cf236ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932028a652db4badbc9ca45d2e21f473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494635e45b98414487258595d4d41e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16fe59408a7148369d0e8399ccb58bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = OwlViTProcessor.from_pretrained(\"google/owlvit-large-patch14\")\n",
    "model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-large-patch14\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918ae3a4-4e34-49da-b8a6-be114c53d734",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OwlViTForObjectDetection(\n",
       "  (owlvit): OwlViTModel(\n",
       "    (text_model): OwlViTTextTransformer(\n",
       "      (embeddings): OwlViTTextEmbeddings(\n",
       "        (token_embedding): Embedding(49408, 768)\n",
       "        (position_embedding): Embedding(16, 768)\n",
       "      )\n",
       "      (encoder): OwlViTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x OwlViTEncoderLayer(\n",
       "            (self_attn): OwlViTAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): OwlViTMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (vision_model): OwlViTVisionTransformer(\n",
       "      (embeddings): OwlViTVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "        (position_embedding): Embedding(3601, 1024)\n",
       "      )\n",
       "      (pre_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder): OwlViTEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x OwlViTEncoderLayer(\n",
       "            (self_attn): OwlViTAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): OwlViTMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual_projection): Linear(in_features=1024, out_features=768, bias=False)\n",
       "    (text_projection): Linear(in_features=768, out_features=768, bias=False)\n",
       "  )\n",
       "  (class_head): OwlViTClassPredictionHead(\n",
       "    (dense0): Linear(in_features=1024, out_features=768, bias=True)\n",
       "    (logit_shift): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (logit_scale): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (elu): ELU(alpha=1.0)\n",
       "  )\n",
       "  (box_head): OwlViTBoxPredictionHead(\n",
       "    (dense0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (dense2): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "953acdb9-1ce8-4ce5-97a1-f80f5865ddb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae86f6e-db78-414d-ab17-552556e08bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import torch\n",
    "from utils.protocols import OwlVit\n",
    "from utils.utils import convert_model_detection\n",
    "from utils.video import read_video\n",
    "from utils.utils import get_file_name, get_gpu_name\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "\n",
    "MODEL= \"owlvit-large-p14-hf\"\n",
    "\n",
    "text = \"face\"\n",
    "BASE_DIR = \"experiments/owlvit\"\n",
    "\n",
    "def process_video(video, frames=[]):\n",
    "    start_time = datetime.now().isoformat()\n",
    "    start = time.time()\n",
    "    \n",
    "    results = {}\n",
    "    for frame_id, frame in read_video(video):\n",
    "        image = Image.fromarray(frame.astype(\"uint8\"))\n",
    "        inputs = processor(text=[[text]], images=image, return_tensors=\"pt\")\n",
    "\n",
    "        inputs = processor(images=image, text=text, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        target_sizes = torch.Tensor([image.size[::-1]])\n",
    "        detections = processor.post_process_object_detection(outputs=outputs, threshold=0.1, target_sizes=target_sizes)\n",
    "        results[frame_id] = convert_model_detection(detections[0])\n",
    "\n",
    "    end = time.time()\n",
    "    end_time = datetime.now().isoformat()\n",
    "    n_frames = frame_id+1 if not frames else len(frames)\n",
    "    \n",
    "    exp =  OwlVit(\n",
    "        model=MODEL,\n",
    "        gpu=get_gpu_name(),\n",
    "        file=video,\n",
    "        prompt=text,\n",
    "        frames=None if not frames else frames,\n",
    "        n_frames=n_frames,\n",
    "        processing_time=end-start,\n",
    "        fps=n_frames/(end-start),\n",
    "        data=results,\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        filename=get_file_name(BASE_DIR, start, MODEL, video)\n",
    "    )\n",
    "    exp.save()\n",
    "    exp.log()\n",
    "    torch.cuda.empty_cache()\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fceb8fc2-5ccd-459c-b5bb-f95a416b0514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-11 11:52:50.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.protocols\u001b[0m:\u001b[36mlog\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mdata/720.mp4 | frames=283 | delta=100.6524441242218 | fps=2.8116555187743986\u001b[0m\n",
      "\u001b[32m2024-06-11 11:54:36.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.protocols\u001b[0m:\u001b[36mlog\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mdata/1080.mp4 | frames=283 | delta=106.67646718025208 | fps=2.6528812537615503\u001b[0m\n",
      "\u001b[32m2024-06-11 11:56:16.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.protocols\u001b[0m:\u001b[36mlog\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mdata/720.mp4 | frames=283 | delta=99.90661096572876 | fps=2.832645380164865\u001b[0m\n",
      "\u001b[32m2024-06-11 11:58:03.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.protocols\u001b[0m:\u001b[36mlog\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mdata/1080.mp4 | frames=283 | delta=106.79778003692627 | fps=2.6498678146881915\u001b[0m\n",
      "\u001b[32m2024-06-11 11:59:44.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.protocols\u001b[0m:\u001b[36mlog\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mdata/720.mp4 | frames=283 | delta=100.53894138336182 | fps=2.8148297177797184\u001b[0m\n",
      "\u001b[32m2024-06-11 12:01:31.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.protocols\u001b[0m:\u001b[36mlog\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mdata/1080.mp4 | frames=283 | delta=106.92804145812988 | fps=2.6466397040556955\u001b[0m\n",
      "\u001b[32m2024-06-11 12:03:11.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.protocols\u001b[0m:\u001b[36mlog\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mdata/720.mp4 | frames=283 | delta=100.086674451828 | fps=2.8275492371984914\u001b[0m\n",
      "\u001b[32m2024-06-11 12:04:57.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.protocols\u001b[0m:\u001b[36mlog\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mdata/1080.mp4 | frames=283 | delta=106.48574376106262 | fps=2.6576327497416723\u001b[0m\n",
      "\u001b[32m2024-06-11 12:06:38.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.protocols\u001b[0m:\u001b[36mlog\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mdata/720.mp4 | frames=283 | delta=100.72283220291138 | fps=2.809690651171145\u001b[0m\n",
      "\u001b[32m2024-06-11 12:08:24.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.protocols\u001b[0m:\u001b[36mlog\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mdata/1080.mp4 | frames=283 | delta=106.2515242099762 | fps=2.6634912026365876\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(5):\n",
    "    vid_hd = process_video(\"data/720.mp4\")\n",
    "    results.append(vid_hd)\n",
    "    vid_fhd = process_video(\"data/1080.mp4\")\n",
    "    results.append(vid_fhd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d4e69a-c183-4acd-a2f9-88b90555aeeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = results[0].columns\n",
    "rows = [result.row for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49ddafb9-ff66-474d-909a-45d9c2ad6b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>gpu</th>\n",
       "      <th>file</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>n_frames</th>\n",
       "      <th>processing_time</th>\n",
       "      <th>fps</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>result_file</th>\n",
       "      <th>prompt</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>owlvit-large-p14-hf</td>\n",
       "      <td>NVIDIA L40</td>\n",
       "      <td>data/720.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>100.652444</td>\n",
       "      <td>2.811656</td>\n",
       "      <td>2024-06-11T11:51:09.388296</td>\n",
       "      <td>2024-06-11T11:52:50.040767</td>\n",
       "      <td>experiments/owlvit/17181066693883045-owlvit-la...</td>\n",
       "      <td>face</td>\n",
       "      <td>{0: [box=[367.13006591796875, 66.2854843139648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>owlvit-large-p14-hf</td>\n",
       "      <td>NVIDIA L40</td>\n",
       "      <td>data/1080.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>106.676467</td>\n",
       "      <td>2.652881</td>\n",
       "      <td>2024-06-11T11:52:50.068282</td>\n",
       "      <td>2024-06-11T11:54:36.744778</td>\n",
       "      <td>experiments/owlvit/17181067700682912-owlvit-la...</td>\n",
       "      <td>face</td>\n",
       "      <td>{0: [box=[548.7283935546875, 98.23286437988281...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>owlvit-large-p14-hf</td>\n",
       "      <td>NVIDIA L40</td>\n",
       "      <td>data/720.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>99.906611</td>\n",
       "      <td>2.832645</td>\n",
       "      <td>2024-06-11T11:54:36.773718</td>\n",
       "      <td>2024-06-11T11:56:16.680358</td>\n",
       "      <td>experiments/owlvit/17181068767737272-owlvit-la...</td>\n",
       "      <td>face</td>\n",
       "      <td>{0: [box=[367.13006591796875, 66.2854843139648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owlvit-large-p14-hf</td>\n",
       "      <td>NVIDIA L40</td>\n",
       "      <td>data/1080.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>106.797780</td>\n",
       "      <td>2.649868</td>\n",
       "      <td>2024-06-11T11:56:16.709576</td>\n",
       "      <td>2024-06-11T11:58:03.507387</td>\n",
       "      <td>experiments/owlvit/17181069767095864-owlvit-la...</td>\n",
       "      <td>face</td>\n",
       "      <td>{0: [box=[548.7283935546875, 98.23286437988281...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>owlvit-large-p14-hf</td>\n",
       "      <td>NVIDIA L40</td>\n",
       "      <td>data/720.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>100.538941</td>\n",
       "      <td>2.814830</td>\n",
       "      <td>2024-06-11T11:58:03.534198</td>\n",
       "      <td>2024-06-11T11:59:44.073168</td>\n",
       "      <td>experiments/owlvit/17181070835342078-owlvit-la...</td>\n",
       "      <td>face</td>\n",
       "      <td>{0: [box=[367.13006591796875, 66.2854843139648...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model         gpu           file  batch_size  n_frames  \\\n",
       "0  owlvit-large-p14-hf  NVIDIA L40   data/720.mp4           1       283   \n",
       "1  owlvit-large-p14-hf  NVIDIA L40  data/1080.mp4           1       283   \n",
       "2  owlvit-large-p14-hf  NVIDIA L40   data/720.mp4           1       283   \n",
       "3  owlvit-large-p14-hf  NVIDIA L40  data/1080.mp4           1       283   \n",
       "4  owlvit-large-p14-hf  NVIDIA L40   data/720.mp4           1       283   \n",
       "\n",
       "   processing_time       fps                  start_time  \\\n",
       "0       100.652444  2.811656  2024-06-11T11:51:09.388296   \n",
       "1       106.676467  2.652881  2024-06-11T11:52:50.068282   \n",
       "2        99.906611  2.832645  2024-06-11T11:54:36.773718   \n",
       "3       106.797780  2.649868  2024-06-11T11:56:16.709576   \n",
       "4       100.538941  2.814830  2024-06-11T11:58:03.534198   \n",
       "\n",
       "                     end_time  \\\n",
       "0  2024-06-11T11:52:50.040767   \n",
       "1  2024-06-11T11:54:36.744778   \n",
       "2  2024-06-11T11:56:16.680358   \n",
       "3  2024-06-11T11:58:03.507387   \n",
       "4  2024-06-11T11:59:44.073168   \n",
       "\n",
       "                                         result_file prompt  \\\n",
       "0  experiments/owlvit/17181066693883045-owlvit-la...   face   \n",
       "1  experiments/owlvit/17181067700682912-owlvit-la...   face   \n",
       "2  experiments/owlvit/17181068767737272-owlvit-la...   face   \n",
       "3  experiments/owlvit/17181069767095864-owlvit-la...   face   \n",
       "4  experiments/owlvit/17181070835342078-owlvit-la...   face   \n",
       "\n",
       "                                                data  \n",
       "0  {0: [box=[367.13006591796875, 66.2854843139648...  \n",
       "1  {0: [box=[548.7283935546875, 98.23286437988281...  \n",
       "2  {0: [box=[367.13006591796875, 66.2854843139648...  \n",
       "3  {0: [box=[548.7283935546875, 98.23286437988281...  \n",
       "4  {0: [box=[367.13006591796875, 66.2854843139648...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1988b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "csv_file = f\"__{MODEL}-{get_gpu_name().replace(' ','_')}-{now.day}-{now.hour}-{now.min}.csv\"\n",
    "df.to_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd7d15-35ef-402b-bb61-2488617967e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
